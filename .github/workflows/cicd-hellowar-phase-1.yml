
name: CI/CD - HelloWar (Phase-1)
run-name: >
  ${{ github.event.inputs.run_description != '' && github.event.inputs.run_description || 'Manual Trigger' }}


on:
  workflow_dispatch:
    inputs:
      run_description:
        description: 'Description of this run'
        required: false
        default: 'Manual Trigger'
      skip_sonar:
        description: 'Skip SonarCloud Scan?'
        type: boolean
        required: false
        default: true
      deploy_version:
        description: 'Version to deploy from Artifactory (used by deploy.sh). Example: 1.0.0'
        required: true
        default: '1.0.0'
      db_enabled:
        description: 'Enable DB telemetry on the backend? (DB_ENABLED)'
        type: choice
        required: false
        default: 'false'
        options:
          - 'false'
          - 'true'
      release_number:
        description: 'Release number exposed via API (RELEASE_NUMBER)'
        required: false
        default: 'manual'

# -----------------------------
# PPPP NOTE:
# - DB is OFF by default.
# - You can enable DB in workflow_dispatch input, OR force it below in code.
# - Force wins over input. Empty string means "no force".
# -----------------------------
env:
  DB_ENABLED_FORCE: ''      # <-- set to 'true' or 'false' to override the input
  RELEASE_NUMBER_FORCE: ''  # <-- set to a value to override the input (optional)

jobs:
  build:
    runs-on: ubuntu-latest
    env:
      JFROG_USER: ${{ secrets.JFROG_USER_CI }}
      JFROG_TOKEN: ${{ secrets.JFROG_TOKEN_CI }}


    steps:
      - name: Show run description
        run: | #multi-line due to yaml parser being picky of : after description
          echo "Run Description: ${{ github.event.inputs.run_description }}"
          echo "Skip SonarCloud Scan: ${{ github.event.inputs.skip_sonar }}"

      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 0 # full history for SonarQube analysis
          
         
      - name: Set up JDK 17
        uses: actions/setup-java@v4
        with:
          distribution: temurin
          java-version: 17
          # This will be used for across runs in this repo so initially disable to test Artifactory Cache.
          cache: maven


      - name: Write Maven settings (.m2/settings.xml)
        run: |
          mkdir -p $HOME/.m2
          cat > $HOME/.m2/settings.xml <<'XML'
          <settings>
            <servers>

              <!-- Read (downloads) via virtual -->
              <server>
                <id>maven-all</id>
                <username>${env.JFROG_USER}</username>
                <password>${env.JFROG_TOKEN}</password>
              </server>

              <server>
                <id>devopsbyte-maven-releases</id>
                <username>${env.JFROG_USER}</username>
                <password>${env.JFROG_TOKEN}</password>
              </server>

              <server>
                <id>devopsbyte-maven-snapshots</id>
                <username>${env.JFROG_USER}</username>
                <password>${env.JFROG_TOKEN}</password>
              </server>

            </servers>

            <mirrors>
              <mirror>
                <id>maven-all</id>
                <url>https://devopsbyte.jfrog.io/artifactory/maven-all</url>
                <mirrorOf>*</mirrorOf>
              </mirror>
            </mirrors>
          </settings>
          XML


      - name: Check Maven cache after restore
        run: |
          echo "After setup-java restore:"
          du -sh ~/.m2/repository || echo "No Maven cache restored."

          echo "--------------------------------------------"
          echo "~/.m2/repository contents (first 50 lines):"
          ls -R ~/.m2/repository | head -50 || true

          echo "--------------------------------------------"
          echo "~/.m2/ contents:"
          ls -l ~/.m2/

          echo "--------------------------------------------"
          echo "settings.xml contents:"
          cat ~/.m2/settings.xml || echo "No settings.xml"
          


      - name: Run unit tests
        run: mvn -B -ntp clean test

      
      - name: SonarCloud Scan
        #if: always() # continue even if previous steps fail (like tests)
        if: ${{ github.event.inputs.skip_sonar != 'true' }}
        continue-on-error: true
        env:
          SONAR_TOKEN: ${{ secrets.SONAR_TOKEN }}
          SONAR_PROJECT_KEY: ${{ vars.SONAR_PROJECT_KEY }}
          SONAR_ORG: ${{ vars.SONAR_ORG }}
        run: |
          mvn -B -ntp verify sonar:sonar \
            -Dsonar.host.url=https://sonarcloud.io \
            -Dsonar.organization=$SONAR_ORG \
            -Dsonar.projectKey=$SONAR_PROJECT_KEY \
            -Dsonar.login=${SONAR_TOKEN}

            # Note: we are NOT using sonar.qualitygate.wait=true in Phase-1.


      - name: Package WAR
        run: mvn -B -ntp -DskipTests package


      - name: Show artifact
        run: ls -l target/*.war || true


      - name: Upload WAR artifact
        uses: actions/upload-artifact@v4
        with:
          name: hello-war                  # constant, easy to download later
          path: target/*.war
          if-no-files-found: error
          retention-days: 14



      - name: Ship Artifact
        run: mvn -B -ntp -DskipTests deploy


  deploy:
    needs: build
    runs-on: ubuntu-latest
    permissions:
      id-token: write
      contents: read
    env:
      ARTIFACTORY_URL: ${{ vars.JFROG_URL }}
      ARTIFACTORY_REPO: ${{ vars.JFROG_REPO }}
      ARTIFACT_GROUP_PATH: ${{ vars.JFROG_ARTIFACT_GROUP_PATH }}
      ARTIFACT_ID: ${{ vars.JFROG_ARTIFACT_ID }}
      ARTIFACT_BASE_VERSION: ${{ vars.JFROG_ARTIFACT_BASE_VER }}
      ARTIFACTORY_USER: ${{ secrets.JFROG_USER_CI  }}
      ARTIFACTORY_TOKEN: ${{ secrets.JFROG_TOKEN_CI  }}
      
    steps:
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-region: us-east-1
          role-to-assume: ${{ secrets.AWS_ROLE_ARN }}
          
      - name: Get EC2 IP dynamically
        id: get_ip
        uses: devopsbyte-internal/cicd-actions/.github/actions/get-ec2-ip@main
        with:
          instance-tag: "hellowar-tomcat-be"
          aws-region: "us-east-1"

      - name: Set EC2 host env
        run: echo "EC2_HOST=${{ steps.get_ip.outputs.ec2_ip }}" >> $GITHUB_ENV
        
      - name: Start SSH agent
        uses: webfactory/ssh-agent@v0.9.0
        with:
          ssh-private-key: ${{ secrets.EC2_SSH_KEY }}

      - name: Run deploy.sh on EC2
        run: |
          ssh -o StrictHostKeyChecking=no ${{ vars.EC2_USER }}@$EC2_HOST \
            "sudo ARTIFACTORY_URL='$ARTIFACTORY_URL' \
                  ARTIFACTORY_REPO='$ARTIFACTORY_REPO' \
                  ARTIFACT_GROUP_PATH='$ARTIFACT_GROUP_PATH' \
                  ARTIFACT_ID='$ARTIFACT_ID' \
                  ARTIFACT_BASE_VERSION='$ARTIFACT_BASE_VERSION' \
                  ARTIFACTORY_USER='$ARTIFACTORY_USER' \
                  ARTIFACTORY_TOKEN='$ARTIFACTORY_TOKEN' \
                  /opt/deploy/deploy.sh '${{ github.event.inputs.deploy_version }}'"


      - name: Write runtime env file + restart Tomcat + health check (PPPP)
        # PPPP NOTE:
        # - We always write /etc/hellowar/hellowar.env so runtime is deterministic.
        # - DB is optional. If enabled but broken, API returns success with a warning.
        run: |
          set -euo pipefail

          ssh -o StrictHostKeyChecking=no "${{ vars.EC2_USER }}@$EC2_HOST"             "DB_ENABLED='$DB_ENABLED' RELEASE_NUMBER='$RELEASE_NUMBER' DB_URL='${{ secrets.DB_URL }}' DB_USER='${{ secrets.DB_USER }}' DB_PASSWORD='${{ secrets.DB_PASSWORD }}' bash -s" << 'EOF'
          set -euo pipefail

          TOMCAT_SERVICE_NAME="tomcat"
          HEALTH_URL="http://localhost:8080/hellowar/api/health"  # <-- NEW Phase-B health endpoint

          ENV_DIR="/etc/hellowar"
          ENV_FILE="${ENV_DIR}/hellowar.env"

          echo "[remote] Writing runtime env file: ${ENV_FILE}"
          sudo mkdir -p "${ENV_DIR}"

          sudo tee "${ENV_FILE}" > /dev/null <<EOT
          RELEASE_NUMBER=${RELEASE_NUMBER}
          DB_ENABLED=${DB_ENABLED}
          EOT

          if [ "${DB_ENABLED}" = "true" ]; then
            # Only write DB creds when DB is enabled
            sudo tee -a "${ENV_FILE}" > /dev/null <<EOT
          DB_URL=${DB_URL}
          DB_USER=${DB_USER}
          DB_PASSWORD=${DB_PASSWORD}
          EOT
          fi

          sudo chmod 640 "${ENV_FILE}"
          sudo chown root:tomcat "${ENV_FILE}" || true

          # Ensure Tomcat reads the env file via a systemd drop-in (idempotent)
          DROPIN_DIR="/etc/systemd/system/${TOMCAT_SERVICE_NAME}.service.d"
          DROPIN_FILE="${DROPIN_DIR}/hellowar-env.conf"
          if ! sudo test -f "${DROPIN_FILE}"; then
            echo "[remote] Creating systemd drop-in to load ${ENV_FILE}"
            sudo mkdir -p "${DROPIN_DIR}"
            sudo tee "${DROPIN_FILE}" > /dev/null <<EOT
          [Service]
          EnvironmentFile=${ENV_FILE}
          EOT
            sudo systemctl daemon-reload
          fi

          echo "[remote] Restarting Tomcat..."
          sudo systemctl restart "$TOMCAT_SERVICE_NAME"

          echo "[remote] Health check: $HEALTH_URL"
          MAX_ATTEMPTS=20
          SLEEP_SECONDS=3
          attempt=1
          while (( attempt <= MAX_ATTEMPTS )); do
            if curl -fsS "$HEALTH_URL" > /dev/null 2>&1; then
              echo "[remote] Health check OK on attempt $attempt"
              exit 0
            fi
            echo "[remote] Health check failed ($attempt/$MAX_ATTEMPTS). Retrying in ${SLEEP_SECONDS}s..."
            sleep "$SLEEP_SECONDS"
            ((attempt++))
          done

          echo "[remote] Health check failed after ${MAX_ATTEMPTS} attempts."
          echo "[remote] ---- Diagnostics (PPPP) ----"
          sudo systemctl status "$TOMCAT_SERVICE_NAME" --no-pager || true
          sudo journalctl -u "$TOMCAT_SERVICE_NAME" -n 200 --no-pager || true
          echo "[remote] webapps dir:"
          ls -la /opt/tomcat/webapps || true
          echo "[remote] ---- End diagnostics ----"
          exit 1
          EOF
